{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T00:09:49.310971Z","iopub.execute_input":"2025-11-10T00:09:49.311455Z","iopub.status.idle":"2025-11-10T00:09:49.318273Z","shell.execute_reply.started":"2025-11-10T00:09:49.311421Z","shell.execute_reply":"2025-11-10T00:09:49.316478Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"### Section 1\n\n## ‚öôÔ∏è Setup\n\n### Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:06:18.558412Z","iopub.execute_input":"2025-11-10T05:06:18.558744Z","iopub.status.idle":"2025-11-10T05:06:18.601306Z","shell.execute_reply.started":"2025-11-10T05:06:18.558720Z","shell.execute_reply":"2025-11-10T05:06:18.600029Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.2 Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:06:26.466947Z","iopub.execute_input":"2025-11-10T05:06:26.467773Z","iopub.status.idle":"2025-11-10T05:07:20.022816Z","shell.execute_reply.started":"2025-11-10T05:06:26.467737Z","shell.execute_reply":"2025-11-10T05:07:20.021735Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"---\n### Section 2\n\n## ü§î Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:20:07.463516Z","iopub.execute_input":"2025-11-10T05:20:07.465708Z","iopub.status.idle":"2025-11-10T05:20:07.473651Z","shell.execute_reply.started":"2025-11-10T05:20:07.465665Z","shell.execute_reply":"2025-11-10T05:20:07.472762Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:20:17.131575Z","iopub.execute_input":"2025-11-10T05:20:17.131937Z","iopub.status.idle":"2025-11-10T05:20:17.137392Z","shell.execute_reply.started":"2025-11-10T05:20:17.131901Z","shell.execute_reply":"2025-11-10T05:20:17.136528Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=\"gemini-2.5-flash-lite\",\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[\n        AgentTool(research_agent),\n        AgentTool(summarizer_agent)\n    ],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:20:48.655444Z","iopub.execute_input":"2025-11-10T05:20:48.655743Z","iopub.status.idle":"2025-11-10T05:20:48.663216Z","shell.execute_reply.started":"2025-11-10T05:20:48.655723Z","shell.execute_reply":"2025-11-10T05:20:48.661916Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"What are the latest advancements in quantum computing and what do they mean for AI?\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:26:01.635497Z","iopub.execute_input":"2025-11-10T05:26:01.635957Z","iopub.status.idle":"2025-11-10T05:26:10.567443Z","shell.execute_reply.started":"2025-11-10T05:26:01.635927Z","shell.execute_reply":"2025-11-10T05:26:10.566403Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Here's a concise summary of the latest advancements in quantum computing and their implications for AI:\n\n*   **Enhanced Processing Power:** Quantum computers, utilizing qubits and superposition, offer exponentially greater processing power than classical computers, enabling AI to tackle complex problems currently out of reach.\n*   **Progress in Quantum Hardware and Error Correction:** Advancements like Google's Willow chip (105 qubits) and prototype logical qubits are crucial steps towards more stable and fault-tolerant quantum computation, making reliable quantum AI more feasible.\n*   **Transformative AI Capabilities:** Quantum AI promises accelerated AI training, improved performance on large datasets, the ability to solve intractable optimization and simulation problems (e.g., in drug discovery and finance), and enhanced natural language processing.\n*   **Efficiency and Sustainability Gains:** Quantum computing can lead to more energy-efficient AI, with examples showing significant energy savings compared to classical supercomputers, addressing a major concern for current large AI models.\n*   **Near-Term Potential and Market Growth:** Though early-stage, quantum AI is seen as a transformative force, akin to AI's state in 2010, with strong market growth projections indicating significant future impact across industries.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n### Section 3\n## üö• Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:45.470414Z","iopub.execute_input":"2025-11-10T05:27:45.471561Z","iopub.status.idle":"2025-11-10T05:27:45.478602Z","shell.execute_reply.started":"2025-11-10T05:27:45.471511Z","shell.execute_reply":"2025-11-10T05:27:45.477333Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\", # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:28:09.893655Z","iopub.execute_input":"2025-11-10T05:28:09.894045Z","iopub.status.idle":"2025-11-10T05:28:09.900055Z","shell.execute_reply.started":"2025-11-10T05:28:09.894019Z","shell.execute_reply":"2025-11-10T05:28:09.899050Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\", # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:28:25.020862Z","iopub.execute_input":"2025-11-10T05:28:25.021184Z","iopub.status.idle":"2025-11-10T05:28:25.027154Z","shell.execute_reply.started":"2025-11-10T05:28:25.021162Z","shell.execute_reply":"2025-11-10T05:28:25.026008Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:28:35.038420Z","iopub.execute_input":"2025-11-10T05:28:35.038795Z","iopub.status.idle":"2025-11-10T05:28:35.044580Z","shell.execute_reply.started":"2025-11-10T05:28:35.038767Z","shell.execute_reply":"2025-11-10T05:28:35.043443Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a blog post about the benefits of multi-agent systems for software developers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:28:40.741656Z","iopub.execute_input":"2025-11-10T05:28:40.742015Z","iopub.status.idle":"2025-11-10T05:28:48.390116Z","shell.execute_reply.started":"2025-11-10T05:28:40.741991Z","shell.execute_reply":"2025-11-10T05:28:48.388923Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here's a blog post outline about the benefits of multi-agent systems for software developers:\n\n## Headline: Unlock Superpowers for Your Code: How Multi-Agent Systems Will Revolutionize Software Development\n\n### Introduction Hook:\n\nImagine your software not just performing tasks, but intelligently coordinating multiple specialized \"brains\" to achieve complex goals, adapt to changing environments, and even learn from its mistakes. This isn't science fiction anymore; it's the reality of Multi-Agent Systems (MAS), and for software developers, it's a game-changer.\n\n### Main Sections:\n\n**1. Enhanced Modularity and Reusability: Building Blocks for Smarter Software**\n\n*   **Decomposition of Complexity:** Break down large, monolithic applications into smaller, independent, and manageable agents, each responsible for a specific function or domain. This drastically simplifies development and debugging.\n*   **Focus on Specialization:** Developers can concentrate on building highly optimized agents for particular tasks, leading to more robust and efficient solutions. These specialized agents can then be reused across different projects.\n*   **Easier Maintenance and Updates:** Updating or modifying a single agent has less impact on the overall system, reducing the risk of introducing bugs and accelerating the development lifecycle.\n\n**2. Increased Robustness and Fault Tolerance: Software That Bounces Back**\n\n*   **Decentralized Architecture:** With multiple agents operating independently, the failure of one agent doesn't necessarily bring down the entire system. Other agents can take over its responsibilities or continue operating.\n*   **Resilience to Errors:** MAS can be designed to detect and handle errors gracefully, rerouting tasks or adapting behavior when unexpected situations arise, making your software more reliable.\n*   **Self-Healing Capabilities:** Advanced MAS can even be programmed to diagnose problems, adapt their strategies, and potentially \"heal\" themselves, reducing the need for constant human intervention.\n\n**3. Powerful Problem-Solving and Adaptability: Intelligence in Action**\n\n*   **Complex Problem Decomposition:** MAS excel at tackling problems that are too complex for a single, centralized program. Agents can collaborate and communicate to find emergent solutions.\n*   **Dynamic Environment Adaptation:** Agents can sense and respond to changes in their operational environment in real-time, allowing software to adapt to shifting user needs, data inputs, or system conditions.\n*   **Intelligent Coordination and Negotiation:** Agents can learn to cooperate, compete, and negotiate with each other to achieve common goals or optimize resource allocation, leading to more intelligent and efficient outcomes.\n\n**4. Accelerated Development and Innovation: Building Faster, Smarter**\n\n*   **Parallel Development:** Different teams can work on individual agents concurrently, significantly speeding up the overall development timeline.\n*   **Leveraging Existing Solutions:** The modular nature of MAS allows developers to integrate pre-built, specialized agents, saving time and effort on common functionalities.\n*   **Exploring New Paradigms:** MAS opens doors to entirely new ways of thinking about software design, enabling the creation of applications with sophisticated behaviors and emergent intelligence.\n\n### Concluding Thought:\n\nEmbracing Multi-Agent Systems isn't just about adopting a new technology; it's about fundamentally evolving how we design, build, and maintain software. By empowering developers with modularity, resilience, and adaptive intelligence, MAS offers a pathway to creating the next generation of powerful, robust, and truly intelligent applications. Are you ready to give your code superpowers?\nWriterAgent > ## Unlock Superpowers for Your Code: How Multi-Agent Systems Will Revolutionize Software Development\n\nImagine your software not just performing tasks, but intelligently coordinating multiple specialized \"brains\" to achieve complex goals, adapt to changing environments, and even learn from its mistakes. This isn't science fiction anymore; it's the reality of Multi-Agent Systems (MAS), and for software developers, it's a game-changer.\n\nAt its core, MAS allows us to decompose complex applications into smaller, independent agents. This enhanced modularity makes development and debugging significantly simpler. Developers can focus on creating highly specialized agents, leading to more robust and efficient solutions that are easily reusable across projects. Plus, maintaining and updating individual agents becomes a breeze, reducing the risk of introducing bugs and accelerating our development cycles.\n\nBeyond modularity, MAS offers unparalleled robustness and fault tolerance. Thanks to their decentralized nature, the failure of one agent doesn't cripple the entire system. Other agents can pick up the slack, ensuring your software remains operational and resilient to errors. Advanced MAS can even exhibit self-healing capabilities, diagnosing and adapting to issues autonomously.\n\nThis leads to powerful problem-solving and incredible adaptability. MAS can tackle problems far too complex for a single program, with agents collaborating to find emergent solutions. They can dynamically respond to changes in their environment, adapting to shifting user needs or data inputs in real-time.\n\nFinally, MAS accelerates development and fosters innovation. Teams can work on individual agents in parallel, speeding up timelines. We can leverage pre-built, specialized agents and explore entirely new paradigms for software design, enabling the creation of applications with sophisticated, emergent intelligence. Embracing MAS isn't just about new tech; it's about evolving how we build software for a smarter future. Are you ready to give your code superpowers?\nEditorAgent > ## Unlock Superpowers for Your Code: How Multi-Agent Systems Will Revolutionize Software Development\n\nImagine your software not just performing tasks, but intelligently coordinating multiple specialized \"brains\" to achieve complex goals, adapt to changing environments, and even learn from its mistakes. This isn't science fiction; it's the burgeoning reality of Multi-Agent Systems (MAS), and for software developers, it represents a paradigm shift with game-changing potential.\n\nAt its heart, MAS empowers us to decompose intricate applications into smaller, independent, and highly specialized agents. This enhanced modularity dramatically simplifies both development and debugging. Developers can focus on crafting agents optimized for specific functions, leading to more robust, efficient, and reusable solutions. Furthermore, maintaining and updating individual agents becomes a far less daunting task, significantly reducing the risk of introducing new bugs and accelerating our overall development cycles.\n\nBeyond improved modularity, MAS offers unparalleled robustness and fault tolerance. Their decentralized nature means that the failure of a single agent doesn't necessarily bring down the entire system. Other agents can seamlessly pick up the slack, ensuring your software remains operational and resilient to errors. Indeed, advanced MAS can even exhibit self-healing capabilities, autonomously diagnosing and adapting to issues.\n\nThis inherent design translates into powerful problem-solving capabilities and incredible adaptability. MAS can tackle challenges far too complex for a single monolithic program, with agents collaborating to discover emergent solutions. They can dynamically respond to changes in their operational environment, adapting in real-time to shifting user needs, fluctuating data inputs, or evolving system conditions.\n\nFinally, MAS accelerates development and cultivates innovation. Teams can work on individual agents concurrently, significantly shortening project timelines. The modular approach allows for the integration of pre-built, specialized agents, saving valuable time and effort. This opens doors to entirely new paradigms for software design, enabling the creation of applications with sophisticated, emergent intelligence. Embracing MAS isn't just about adopting new technology; it's about fundamentally evolving how we build software for a smarter, more dynamic future. Are you ready to give your code superpowers?\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 4\n## üõ£Ô∏è Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:30:01.959176Z","iopub.execute_input":"2025-11-10T05:30:01.959539Z","iopub.status.idle":"2025-11-10T05:30:01.968195Z","shell.execute_reply.started":"2025-11-10T05:30:01.959515Z","shell.execute_reply":"2025-11-10T05:30:01.966658Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:30:14.804686Z","iopub.execute_input":"2025-11-10T05:30:14.805075Z","iopub.status.idle":"2025-11-10T05:30:14.812010Z","shell.execute_reply.started":"2025-11-10T05:30:14.805049Z","shell.execute_reply":"2025-11-10T05:30:14.810619Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:30:18.677181Z","iopub.execute_input":"2025-11-10T05:30:18.677602Z","iopub.status.idle":"2025-11-10T05:30:18.685629Z","shell.execute_reply.started":"2025-11-10T05:30:18.677567Z","shell.execute_reply":"2025-11-10T05:30:18.684480Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\", # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:30:23.132584Z","iopub.execute_input":"2025-11-10T05:30:23.132999Z","iopub.status.idle":"2025-11-10T05:30:23.139105Z","shell.execute_reply.started":"2025-11-10T05:30:23.132974Z","shell.execute_reply":"2025-11-10T05:30:23.137785Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:30:50.155281Z","iopub.execute_input":"2025-11-10T05:30:50.155562Z","iopub.status.idle":"2025-11-10T05:30:50.161692Z","shell.execute_reply.started":"2025-11-10T05:30:50.155543Z","shell.execute_reply":"2025-11-10T05:30:50.160610Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Run the daily executive briefing on Tech, Health, and Finance\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:30:54.646339Z","iopub.execute_input":"2025-11-10T05:30:54.646662Z","iopub.status.idle":"2025-11-10T05:31:00.333527Z","shell.execute_reply.started":"2025-11-10T05:30:54.646641Z","shell.execute_reply":"2025-11-10T05:31:00.332711Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **Key AI/ML Trends**\n\n**1. Generative AI Advancement:** Generative models are evolving beyond text to create complex multimedia content like graphics, video, and music. This trend is significantly expanding artistic expression and practical applications. Major players include Google (with models like Imagen and Muse), OpenAI, and Microsoft.\n\n**2. Shift to Smaller, More Efficient Models:** There's a growing trend towards \"Small Language Models\" (SLMs) as a more efficient alternative to Large Language Models (LLMs), particularly for specific tasks and resource-constrained environments.\n\n**3. Multimodal AI:** AI systems are increasingly capable of processing and integrating information from various modalities such as images, text, audio, and video. This allows for more sophisticated understanding and interaction. Companies like Google and Microsoft are key in this development.\n\n**Companies Involved:** Key companies driving these trends include Google, NVIDIA, Microsoft, Amazon, OpenAI, and Databricks.\n\n**Potential Impact:** These advancements promise to revolutionize industries by enhancing productivity, automating complex tasks, and enabling new forms of creativity. However, they also bring challenges related to data privacy, ethical considerations, and workforce adaptation.\nHealthResearcher > Here's a concise briefing on recent breakthroughs in Technology, Health, and Finance:\n\n**Health:** Gene therapy is showing remarkable success, enabling a deaf child to hear and holding promise for inherited diseases and even cancer treatment. CAR T-cell therapy is offering new hope for brain cancers by reengineering a patient's immune cells. Furthermore, induced pluripotent stem cells are being used to restore vision in patients with corneal stem cell deficiency.\n\n**Technology:** Agentic AI, capable of performing tasks independently, is emerging as a top trend for 2025, alongside advancements in spatial computing and micro LLMs. Climate technology is also gaining significant traction, focusing on reducing environmental impact through innovations in energy efficiency and carbon capture.\n\n**Finance:** Artificial intelligence is revolutionizing financial services through advanced portfolio management and risk assessment. Embedded finance is seamlessly integrating financial services into non-financial platforms, with the sector projected to grow significantly. Decentralized finance (DeFi) is maturing into a robust ecosystem with enhanced security and scalability.\nFinanceResearcher > **Tech:**\n\n*   **Agentic AI & Context Engineering:** AI is evolving beyond simple chatbots to autonomous agents capable of complex tasks. Context engineering, which involves meticulously preparing data for AI models, is crucial for reliable performance.\n    *   Market Implications: Increased automation in software development, customer service, and complex workflow management. Demand for specialized AI infrastructure and orchestration tools, like Kubernetes for GPUs, will rise.\n    *   Future Outlook: Agentic AI will become more sophisticated, integrating real-time data and adaptive decision-making. Context engineering will be a key skill for AI developers.\n*   **Quantum Computing Advancements:** Quantum computing continues to develop, showing promise in areas like finance for optimization and risk analysis, and in manufacturing for supply chain efficiency.\n    *   Market Implications: Potential for breakthroughs in complex problem-solving across industries. Increased investment in R&D and specialized hardware.\n    *   Future Outlook: As quantum systems mature and become more accessible, their practical applications will expand significantly.\n\n**Health:**\n\n*   **Personalized Healthcare & Genomics:** Advances in genomics and the explosion of health data (wearables, medical records) are driving personalized medicine.\n    *   Market Implications: Growth in diagnostic tools, targeted therapies, and health-tech platforms. Increased focus on data privacy and security.\n    *   Future Outlook: More tailored treatments and preventative strategies based on individual genetic makeup and lifestyle data.\n*   **Mental Health Technology:** Technological solutions, including VR/AR therapy, AI-powered chatbots, and increased corporate focus on mental well-being, are revolutionizing mental healthcare delivery.\n    *   Market Implications: Expansion of digital mental health services, employee wellness programs, and demand for accessible, stigma-free support.\n    *   Future Outlook: Greater integration of technology into mental healthcare, improving accessibility and early intervention.\n\n**Finance:**\n\n*   **AI Integration in Finance:** AI is moving from a support role to a central system for risk analysis, compliance, customer engagement, and trading accuracy.\n    *   Market Implications: Enhanced efficiency and accuracy in financial operations, leading to potential job shifts towards data interpretation and AI management. Increased investment in AI infrastructure by financial institutions.\n    *   Future Outlook: AI will drive greater automation and data-driven decision-making across all financial sectors.\n*   **Regulatory Evolution and Transparency:** New regulations (e.g., DORA, PSD3) are strengthening cybersecurity and data integrity, while transparency is becoming a key trust indicator for investors.\n    *   Market Implications: Increased compliance costs but also greater investor confidence and corporate resilience. Focus on verified data and clear licensing.\n    *   Future Outlook: A more regulated and transparent financial landscape, with technology and regulation increasingly intertwined.\nAggregatorAgent > ## Executive Summary: Tech, Health, and Finance Briefing\n\nThe convergence of AI and data is driving transformative advancements across technology, health, and finance. **Agentic AI** and **multimodal capabilities** are leading technological innovation, enabling more sophisticated, autonomous systems that can process diverse data types. This trend is mirrored by the rise of **smaller, more efficient AI models** and the crucial role of **context engineering** for reliable performance.\n\nIn healthcare, breakthroughs in **gene therapy, CAR T-cell therapy, and induced pluripotent stem cells** are revolutionizing treatment for genetic diseases, cancers, and vision loss. These advancements are closely linked to the growth in **personalized healthcare and genomics**, fueled by vast amounts of health data. **Mental health technology** is also rapidly expanding, leveraging AI and immersive technologies for greater accessibility.\n\nThe financial sector is undergoing significant AI-driven change, with **AI integration** enhancing risk assessment, portfolio management, and operational efficiency. **Embedded finance** and maturing **Decentralized Finance (DeFi)** further illustrate this evolution. Emerging technologies like **quantum computing** hold immense potential for complex problem-solving in finance and beyond.\n\nKey common themes include the pervasive impact of AI, the critical importance of data, and the increasing need for specialized infrastructure and adaptable workforces. While these advancements promise unprecedented productivity and innovation, they also necessitate careful consideration of data privacy, ethical implications, and regulatory frameworks to ensure responsible growth.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 5\n## ‚û∞ Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\", # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:31:53.506090Z","iopub.execute_input":"2025-11-10T05:31:53.506463Z","iopub.status.idle":"2025-11-10T05:31:53.513395Z","shell.execute_reply.started":"2025-11-10T05:31:53.506439Z","shell.execute_reply":"2025-11-10T05:31:53.512308Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\", # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:32:05.240514Z","iopub.execute_input":"2025-11-10T05:32:05.240880Z","iopub.status.idle":"2025-11-10T05:32:05.249075Z","shell.execute_reply.started":"2025-11-10T05:32:05.240829Z","shell.execute_reply":"2025-11-10T05:32:05.247903Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:32:29.532961Z","iopub.execute_input":"2025-11-10T05:32:29.534081Z","iopub.status.idle":"2025-11-10T05:32:29.540131Z","shell.execute_reply.started":"2025-11-10T05:32:29.534042Z","shell.execute_reply":"2025-11-10T05:32:29.539089Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    \n    output_key=\"current_story\", # It overwrites the story with the new, refined version.\n    tools=[FunctionTool(exit_loop)], # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:33:02.205190Z","iopub.execute_input":"2025-11-10T05:33:02.205477Z","iopub.status.idle":"2025-11-10T05:33:02.211508Z","shell.execute_reply.started":"2025-11-10T05:33:02.205456Z","shell.execute_reply":"2025-11-10T05:33:02.210388Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2, # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:33:19.452684Z","iopub.execute_input":"2025-11-10T05:33:19.453043Z","iopub.status.idle":"2025-11-10T05:33:19.460038Z","shell.execute_reply.started":"2025-11-10T05:33:19.453018Z","shell.execute_reply":"2025-11-10T05:33:19.458795Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:33:23.947699Z","iopub.execute_input":"2025-11-10T05:33:23.948533Z","iopub.status.idle":"2025-11-10T05:33:31.135142Z","shell.execute_reply.started":"2025-11-10T05:33:23.948497Z","shell.execute_reply":"2025-11-10T05:33:31.134173Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salt spray was Elias‚Äôs constant companion, a cold kiss against his weathered face. For thirty years, the lighthouse had been his world, its beam a steady pulse against the encroaching dark. One blustery evening, as he stoked the lamp, a glint caught his eye. Tucked within a crevice of the rock face, usually obscured by tide, was a rolled parchment.\n\nUnfurling it by lamplight, Elias gasped. It wasn't paper, but some strange, leathery material. Strange symbols pulsed with a soft, aquamarine glow, forming what looked undeniably like a map. But not of any sea he knew. This chart depicted islands of impossible shapes, swirling currents of light, and a single, radiant X. His heart hammered. The sea, his familiar domain, suddenly felt vast and terribly, wonderfully, unknown.\nCriticAgent > This is a strong start to a story, creating immediate intrigue and setting a clear atmosphere.\n\nHere are 2-3 actionable suggestions for improvement:\n\n1.  **Deepen Elias's internal reaction:** While his heart hammering and feeling the sea as unknown is good, consider showing *how* this discovery changes his perspective *in that moment*. Does he look at his familiar lamp with new eyes? Does he feel a surge of adrenaline, or a flicker of fear mixed with excitement? Adding a specific thought or physical reaction beyond just his heart beating would further immerse the reader in his experience.\n2.  **Hint at the \"why\" of the map:** The map is undeniably mysterious, but a subtle hint as to its potential origin or purpose could elevate the hook. Is there any indication on the map itself, beyond the X, that suggests what it might lead to? Perhaps the symbols, when examined closer, bear a resemblance to something Elias has encountered or heard legends of, even if distantly. This doesn't need to be revealed, just subtly suggested.\n3.  **Strengthen the sensory details of the map:** You mention the \"leathery material\" and \"aquamarine glow,\" which are good. To make it even more impactful, consider adding one more sensory detail. Does it have a scent? Is the material cool or warm to the touch? Does the light emanating from the symbols cast a peculiar shadow?\nRefinerAgent > The salt spray was Elias‚Äôs constant companion, a cold kiss against his weathered face. For thirty years, the lighthouse had been his world, its beam a steady pulse against the encroaching dark. One blustery evening, as he stoked the lamp, a glint caught his eye. Tucked within a crevice of the rock face, usually obscured by tide, was a rolled parchment.\n\nUnfurling it by lamplight, Elias gasped. It wasn't paper, but some strange, leathery material that felt unnervingly cool against his fingertips. Strange symbols pulsed with a soft, aquamarine glow, casting dancing shadows on the stone walls of the lantern room. The symbols, when examined closer, seemed to possess a familiar, almost serpentine quality, like the ancient sea serpents whispered about in sailors' tales. It formed what looked undeniably like a map. But not of any sea he knew. This chart depicted islands of impossible shapes, swirling currents of light, and a single, radiant X. His heart hammered against his ribs, a frantic drumbeat of adrenaline and a thrill of fear. He looked at his familiar lamp, its steady glow now seeming mundane, and then back at the alien chart. The sea, his familiar domain, suddenly felt vast and terribly, wonderfully, unknown. A faint, briny scent, like ozone after a storm, emanated from the leathery surface, a scent that spoke of places far beyond the horizon.\nCriticAgent > This revised version is a significant improvement! You've incorporated the suggested refinements beautifully.\n\nAPPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n### Section 6\n## Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}